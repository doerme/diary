# something about TCP && HTTP/2

## TCP
今天听讲了一些关于计算机网络主要相关 TCP 的东西, 顺便做总结.
前端是需要时常抓包观察网络请求是否正常或者页面的出错信息的, 所以抓包技能前端必备(我在这方面并不熟悉,惭愧...), 而使用 wireshark 对于观察 IP 包来说我们会可以看到 IP 包可以选择是否分片来传输, 看到 TCP 会有整个包的循环校验和来确定包的数据有没有出错或者被修改, 而 IP 只有头检验和.
常常在将前端性能, 其实归根结底,就是对网络时延的优化, 对网络时延上又不能不讲 TCP, 因为我们日常广泛地使用了 TCP 协议, 对于网络时延的计算肯定会讲到往返时间, 其实为什么要计算往返时间, 其实是因为我们不能真实地实时地计算一次传输单程共花多少时间, 因为不可能在客户端上用秒表计时, 所以我们使用一个往返时间, 来表示两端之间传输的时间 * 2.它是非常关键的标准值.那我们怎么得到 RTT 呢?有两种方式: 1. 根据 ACK, 当 ACK 返回来的时候,我们就知道往返时间是多少了, 但是缺点就是我们并不知道这个 ack 是否是重传的或者是另一端的 delay ACK(延迟发送 ACK, 积累到一定数量的 ACK 才发送) 的, 2. 根据时间戳, 在每个 ACK 带上时间戳的信息, 但是这样就损耗了 CPU 的计算能力, 开销比较大. 我们一般是使用平滑 rtt, => srtt = (7 * oldrtt + newrtt) >> 3, 也即是 7 个旧的 rtt 加上一个目前的 rtt 然后和右移 3 位.这里右移计算而不是采用除法是因为第一快, 第二不想要浮点数.
得到 rtt 还不是最有用的东西, 有用的东西是 RTO, rtt 可以用于计算 RTO, 也就是控制数据重传的时间.只有这个时间控制好了, 才能最大限度地使用带宽.
我们知道 ACK 是不能乱发的, 因为在 TCP 控制时延里面就需要准确使用 ACK 来实现.网络情况好的时候我们会倾向于使用 NACK 来发送信息, 因为如果我们网络情况比较好的时候, 如果使用 ACK,有可能会使网络充斥 ACK,导致浪费了带宽, 网络阻塞的原因一般来说一般有三点: 带宽情况, 内存空间大小, CPU 处理能力. 带宽是由设备的物理属性导致的, 像 ADSL 可能就只能接收 512kb 的下限, 内存空间就是路由器的排队数量, 如果过多可能排队过长甚至丢包, CPU 就是路由器查询路由表将分组交换到其他端口的能力.以上这些都可能导致时延增加或者丢包. 
所以为了拥塞避免,TCP 有慢启动机制, 所谓慢启动就是一开始用 1 个包发送, 然后用 2 的指数级来增加发送的数量, 一旦到达初始设置的阀值就停止用指数级, 然后使用拥塞避免,也即是 + 1 的增长来控制,当接收到三个重复的 ACK 的时候, 我们会看作是丢包了, 网络开始拥塞了, 所以会将发送包数量变为拥塞控制最高点的一般来做开始值, 而不是用 1, 而这个就是快速恢复了.我们仔细看这个算法, 其实会有很多优化的地方, 其中使用丢包来判断网络拥塞可能会使网络带宽利用率不高, 如果想加快, 应该使用检测时延的方法来判断, 也就是可以使用一些像 TCP-BBR 这样的算法来判断.
总结来说, 如果想提高网络传输效率, 第一要低时延, 第二要准确, 这里准确的意思是要准确知道网络带宽什么时候能塞满, 能够有多大.
## HTTP/2
关于 HTTP/2,它有很多很好的特性.
第一就是二进制传输, 我们知道 HTTP/1.x 是使用文本传输的, 而文本可能会有一个编码的问题, 如果要做全适应保持健壮性就要做一些额外的工作, 但是二进制就不会有这个问题, 因为都是 01 这样的数据.
第二就是多路复用, 首先就要说明这个和 keep-alive 的区别是什么, keep-alive 是 HTTP/1.1 采用的策略, 通过复用 TCP 连接, 抛弃传统的一问一答关闭连接的步骤, 也就是一个 HTML 页面上的与服务器的请求都通过一个 TCP 连接来完成, 节省了重开一个 TCP 连接的开销, 但是问题在于这里存在一个线头阻塞的问题, 也就是说虽然是共用了一个 TCP 连接, 但是前一个 HTTP 请求还是会阻塞了后面一个 HTTP 请求.就像银行柜台, 你还是要一个一个排队来处理事务.但是这样并没有根本地解决 HTTP 时延大这个问题(排队还是消耗了大量的时延的).为了消除时延我们才使用了像雪碧图, js 文件拼接,内联, 或者使用不同的 CDN 静态资源域名同时加载资源等等. 而在 HTTP/2 中其实是使用了流这样的概念, 它是真正地并发, 将多个 HTTP 请求同时发送, 大大减少了时延, 举个例子就是像货运火车, 货运火车将很多不同车厢拼接起来, 然后运输到终点站, 然后再分开送到各自的目的地.流中会有很多帧, 请求都分为了一个个帧来发送.而且这些流都会有优先级, 也就是说, http/2 协议知道哪些资源需要先被传输过去, 就像全是图片的网站但是 http/2 可以决定哪些图片会先被传输完, 这也就是说有可能我们之前所说的那些 css 文件放在 html 头部, js 放在 html 末尾可能没有意义, 因为 http 可以决定哪些资源先被传输.
第三就是头部压缩, 我们知道有时候传输的数据量并不大, 可能 http 头部占据的数据量比我们本身需要传输的数据还大, 所以如果多个 HTTP 请求的头部, http/2 会压缩头部, 并且如果头部发生改变,那么只需要发送那个改变的头部就可以了.
第四就是服务器推, 它的主要思想是为了提供客户端的缓存问题, 在服务器知道客户端可能需要这个资源的时候, 服务器在客户端请求之前主动推送数据到客户端上.
HTTP/2 需要在 HTTPS 的基础上使用, 这样增加了一层 TLS 层的握手, 也就会增加了服务端的计算负荷.这是它的缺陷.

虽然 HTTP/2 需要全站升级 HTTPS ,但是我觉得它在性能方面非常吸引我们, 而且它是向下兼容的, 我们应该积极升级 HTTPS & HTTP/2.

inks:
[alloyteam 关于 HTTP 的博文](http://www.alloyteam.com/2016/07/httphttp2-0spdyhttps-reading-this-is-enough/)
[HTTP2](https://ye11ow.gitbooks.io/http2-explained/content/part8.html)